{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from webui.utils import ObjectNamespace\n",
    "from webui.chat import Character\n",
    "import sounddevice as sd\n",
    "from llama_cpp import Llama, LlamaGrammar\n",
    "\n",
    "def chat(char,prompt=\"Continue the story without me\"):\n",
    "    full_response = \"\"\n",
    "    for response in char.generate_text(prompt):\n",
    "        full_response += response\n",
    "    audio = char.text_to_speech(full_response)\n",
    "    if audio: sd.play(*audio)            \n",
    "    char.messages.append({\"role\": char.user, \"content\": prompt}) #add user prompt to history\n",
    "    char.messages.append({\n",
    "        \"role\": char.name,\n",
    "        \"content\": full_response,\n",
    "        \"audio\": audio\n",
    "    })\n",
    "    return full_response\n",
    "\n",
    "def get_function(char, query, threshold=1.):\n",
    "    results = char.ltm.get_query(query=query,include=[\"metadatas\", \"distances\"],type=\"function\",threshold=threshold)\n",
    "    if len(results): # found function\n",
    "        metadata = results[0][\"metadata\"]\n",
    "        return metadata\n",
    "    else: return None\n",
    "\n",
    "def get_args(char, arguments, template, prompt, retries=3):\n",
    "    response = char.LLM(f\"\"\"\n",
    "              <|im_start|>system\n",
    "              Complete these arguments ({arguments}) using this template ({template}) while following the user's request.<|im_end|>\n",
    "              <|im_start|>user\n",
    "              {prompt}<|im_end|>\n",
    "              \"\"\",grammar=grammar,stop=[\"<|im_start|>\",\"<|im_end|>\"])\n",
    "    try:\n",
    "        args = json.loads(response[\"choices\"][0][\"text\"])\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        args = get_args(char, arguments, template, prompt, retries-1) if retries>0 else None\n",
    "    return args        \n",
    "\n",
    "grammar = LlamaGrammar.from_file(\"./models/LLM/json.gbnf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This is a demo to showcase function calling\n",
    "\"\"\"\n",
    "character = Character(\n",
    "    character_file=\"./models/Characters/Amaryllis.json\",\n",
    "    model_file=\"./models/LLM/mistral-7b-openorca.Q4_K_M.gguf\"\n",
    ")\n",
    "character.LLM = Llama(\n",
    "    character.model_file,\n",
    "    n_ctx=character.model_data[\"params\"][\"n_ctx\"],\n",
    "    n_gpu_layers=character.model_data[\"params\"][\"n_gpu_layers\"],\n",
    "    verbose=True\n",
    ")\n",
    "character.loaded=True\n",
    "character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We first define the list of function definitions and put them to a vector database.\n",
    "The description should be potential user prompts that can trigger the function.\n",
    "\n",
    "arguments: list of argument names that the function uses\n",
    "**kwargs: dictionary of [type: data type, description: description of argument, required: whether it is required]\n",
    "\"\"\"\n",
    "functions = [\n",
    "    ObjectNamespace(\n",
    "        description = \"Can you please play a song for me?|I would love to hear some music.|Can you choose a song for me?Play a song, please.|Letâ€™s enjoy some music together\",\n",
    "        function = \"play_song\",\n",
    "        arguments = [\"name\",\"search\"],\n",
    "        name = {\"type\": \"str\", \"description\": \"name of the song\", \"required\": True},\n",
    "        search = {\"type\": \"boolean\", \"description\": \"search for the song if it doesn't exist\"},\n",
    "    ),\n",
    "]\n",
    "\n",
    "for data in functions:\n",
    "    character.ltm.add_function(**data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Can you play the song despacito for me?\"\n",
    "metadata = get_function(character,prompt,threshold=1.)\n",
    "print(f\"{metadata=}\")\n",
    "args = get_args(character, metadata['arguments'], metadata['template'], prompt)\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_song(name,search): # dummy function\n",
    "    print(f\"playing {name}. search song on youtube if it doesn't exist: {search}\")\n",
    "eval(metadata[\"function\"])(**args) # evaluate the song"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RVC-Chat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
