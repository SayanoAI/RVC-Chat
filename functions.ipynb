{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root ::= object \n",
      "object ::= [{] ws object_11 [}] ws \n",
      "value ::= object | array | string | number | value_6 ws \n",
      "array ::= [[] ws array_15 []] ws \n",
      "string ::= [\"] string_18 [\"] ws \n",
      "number ::= number_19 number_25 number_29 ws \n",
      "value_6 ::= [t] [r] [u] [e] | [f] [a] [l] [s] [e] | [n] [u] [l] [l] \n",
      "ws ::= ws_31 \n",
      "object_8 ::= string [:] ws value object_10 \n",
      "object_9 ::= [,] ws string [:] ws value \n",
      "object_10 ::= object_9 object_10 | \n",
      "object_11 ::= object_8 | \n",
      "array_12 ::= value array_14 \n",
      "array_13 ::= [,] ws value \n",
      "array_14 ::= array_13 array_14 | \n",
      "array_15 ::= array_12 | \n",
      "string_16 ::= [^\"\\] | [\\] string_17 \n",
      "string_17 ::= [\"\\/bfnrt] | [u] [0-9a-fA-F] [0-9a-fA-F] [0-9a-fA-F] [0-9a-fA-F] \n",
      "string_18 ::= string_16 string_18 | \n",
      "number_19 ::= number_20 number_21 \n",
      "number_20 ::= [-] | \n",
      "number_21 ::= [0-9] | [1-9] number_22 \n",
      "number_22 ::= [0-9] number_22 | \n",
      "number_23 ::= [.] number_24 \n",
      "number_24 ::= [0-9] number_24 | [0-9] \n",
      "number_25 ::= number_23 | \n",
      "number_26 ::= [eE] number_27 number_28 \n",
      "number_27 ::= [-+] | \n",
      "number_28 ::= [0-9] number_28 | [0-9] \n",
      "number_29 ::= number_26 | \n",
      "ws_30 ::= [ <U+0009><U+000A>] ws \n",
      "ws_31 ::= ws_30 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "from_string grammar:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from webui.utils import ObjectNamespace\n",
    "from webui.chat import Character\n",
    "import sounddevice as sd\n",
    "from llama_cpp import Llama, LlamaGrammar\n",
    "\n",
    "def chat(char,prompt=\"Continue the story without me\"):\n",
    "    full_response = \"\"\n",
    "    for response in char.generate_text(prompt):\n",
    "        full_response += response\n",
    "    audio = char.text_to_speech(full_response)\n",
    "    if audio: sd.play(*audio)            \n",
    "    char.messages.append({\"role\": char.user, \"content\": prompt}) #add user prompt to history\n",
    "    char.messages.append({\n",
    "        \"role\": char.name,\n",
    "        \"content\": full_response,\n",
    "        \"audio\": audio\n",
    "    })\n",
    "    return full_response\n",
    "\n",
    "def get_function(char, query, threshold=1.):\n",
    "    results = char.ltm.get_query(query=query,include=[\"metadatas\", \"distances\"],type=\"function\",threshold=threshold)\n",
    "    if len(results): # found function\n",
    "        metadata = results[0][\"metadata\"]\n",
    "        return metadata\n",
    "    else: return None\n",
    "\n",
    "def get_args(char, arguments, template, prompt, retries=3):\n",
    "    response = char.LLM(f\"\"\"\n",
    "              <|im_start|>system\n",
    "              Complete these arguments ({arguments}) using this template ({template}) while following the user's request.<|im_end|>\n",
    "              <|im_start|>user\n",
    "              {prompt}<|im_end|>\n",
    "              \"\"\",grammar=grammar,stop=[\"<|im_start|>\",\"<|im_end|>\"])\n",
    "    try:\n",
    "        args = json.loads(response[\"choices\"][0][\"text\"])\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        args = get_args(char, arguments, template, prompt, retries-1) if retries>0 else None\n",
    "    return args        \n",
    "\n",
    "grammar = LlamaGrammar.from_file(\"./models/LLM/json.gbnf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 0 | VSX = 0 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading sound c:\\Users\\hongb\\Documents\\repos\\RVC-Chat\\.cache\\tts\\edge\\en-US-JennyNeural\\e1e11efedb8cce4ce31f5883ee9a04af.wav (738816,) 16000\n",
      "vc_single unused args: {'model_name': 'Mae_v2'}\n",
      "before remix: shape=(738816,), max=0.7178962826728821, min=-0.7133902311325073, mean=1.0637065315677319e-05 sr=16000\n",
      "after remix: shape=(738816,), max=0.949999988079071, min=-0.9440370798110962, mean=1.4076164006837644e-05, sr=16000\n",
      "Attempting to load c:\\Users\\hongb\\Documents\\repos\\RVC-Chat\\models\\RVC/.index\\Mae_v2_40k.index....\n",
      "loaded index: <faiss.swigfaiss.IndexIVFFlat; proxy of <Swig Object of type 'faiss::IndexIVFFlat *' at 0x000001F1662A6780> >\n",
      "f0_method=rmvpe\n",
      "Returning completed audio...\n",
      "-------------------\n",
      "Using index:c:\\Users\\hongb\\Documents\\repos\\RVC-Chat\\models\\RVC/.index\\Mae_v2_40k.index.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<webui.chat.Character at 0x1f0ab6a8fd0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "This is a demo to showcase function calling\n",
    "\"\"\"\n",
    "character = Character(\n",
    "    character_file=\"./models/Characters/Amaryllis.json\",\n",
    "    model_file=\"./models/LLM/mistral-7b-openorca.Q4_K_M.gguf\"\n",
    ")\n",
    "character.LLM = Llama(\n",
    "    character.model_file,\n",
    "    n_ctx=character.model_data[\"params\"][\"n_ctx\"],\n",
    "    n_gpu_layers=character.model_data[\"params\"][\"n_gpu_layers\"],\n",
    "    verbose=True\n",
    ")\n",
    "character.loaded=True\n",
    "character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We first define the list of function definitions and put them to a vector database.\n",
    "The description should be potential user prompts that can trigger the function.\n",
    "\n",
    "arguments: list of argument names that the function uses\n",
    "**kwargs: dictionary of [type: data type, description: description of argument, required: whether it is required]\n",
    "\"\"\"\n",
    "functions = [\n",
    "    ObjectNamespace(\n",
    "        description = \"Can you please play a song for me?|I would love to hear some music.|Can you choose a song for me?Play a song, please.|Letâ€™s enjoy some music together\",\n",
    "        function = \"play_song\",\n",
    "        arguments = [\"name\",\"search\"],\n",
    "        name = {\"type\": \"str\", \"description\": \"name of the song\", \"required\": True},\n",
    "        search = {\"type\": \"boolean\", \"description\": \"search for the song if it doesn't exist\"},\n",
    "    ),\n",
    "]\n",
    "\n",
    "for data in functions:\n",
    "    character.ltm.add_function(**data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata={'arguments': '[\"name\", \"search\"]', 'function': 'play_song', 'hnsw:space': 'cosine', 'template': '{\"name\": {\"type\": \"str\", \"description\": \"name of the song\", \"required\": true}, \"search\": {\"type\": \"boolean\", \"description\": \"search for the song if it doesn\\'t exist\"}}', 'type': 'function'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'Despacito', 'search': True}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"Can you play the song despacito for me?\"\n",
    "metadata = get_function(character,prompt,threshold=1.)\n",
    "print(f\"{metadata=}\")\n",
    "args = get_args(character, metadata['arguments'], metadata['template'], prompt)\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "playing Despacito. search song on youtube if it doesn't exist: True\n"
     ]
    }
   ],
   "source": [
    "def play_song(name,search): # dummy function\n",
    "    print(f\"playing {name}. search song on youtube if it doesn't exist: {search}\")\n",
    "eval(metadata[\"function\"])(**args) # evaluate the song"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RVC-Chat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
